{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Redes Neuronales Convolucionales para la detección de puntos anatómicos en imágenes cefálicas laterales</h1>\n",
    "\n",
    "<p>En este proyecto busco utilizar algunas arquitecturas de redes neuronales convolucionales para determinar cual de ellas se adecúa mejor a la detección de puntos anatómicos en imágenes radiográficas cefálicas laterales, intentaré hacerlo lo mas sencillo posible.</p>\n",
    "\n",
    "<h2 style=\"color:red;\">Data Utilizada</h2>\n",
    "\n",
    "<p>Para realizar esta investigación, voy a usar una data disponible de forma gratuita en <a href=\"http://www-o.ntust.edu.tw/~cweiwang/ISBI2015/challenge1/index.html\">Dataset</a>, de la misma, solo utilice la data con labels \"senior\".</p>\n",
    "\n",
    "<h3>Breve Descripción de la data</h3>\n",
    "\n",
    "<p>Los datos a utilizar consisten en 400 imágenes de imágenes radiográficas cefálicas laterales (escala de grises) junto con un vector que indica la posición de 19 puntos anatómicos, etiquetados por un especialista senior en el área (ver link del dataset para mayor detalle.</p>\n",
    "\n",
    "<h2 style=\"color:red;\">Preprocesamiento y Data Augmentation</h2>\n",
    "\n",
    "<p>Para hacer el modelo más general, las imágenes fueron preprocesadas para cumplir con:</p>\n",
    "* Imágenes cuadradas de 128x128 pixeles.\n",
    "* Imágenes normalizadas (rango de intensidad de pixeles de -1 a 1).\n",
    "* Para tener mayor cantidad de datos y evitar overfit, se aumentó la data al hacer flip horizontal y vertical, para un total de 1200 imágenes con sus labels (400 originales + 400 flip horizontal + 400 flip vertical).\n",
    "* Igualmente, para evitar overfit, las imágenes están organizadas en 1 original - 1 flip h - 1 flip v. Nota: Es cierto que lo ideal sería mezclar todo, sin embargo, las imágenes \"flipeadas\" distan tanto de la original que no creo que el efecto sea tan evidente, de todas formas es un punto a explorar.\n",
    "* El training set consta de 900 imágenes, mientras que el test set de 300 imágenes.\n",
    "\n",
    "<h2 style=\"color:red;\">Entorno de Ejecución</h2>\n",
    "\n",
    "<p>Debido a diversas limitantes, la mejor opción que tengo disponible es, sin dudas, usando el entorno acelerado por GPU en Google Colab (no se imaginan cuanto lo agardezco), la forma de setearlo la obtuve de este post de <a href=\"https://www.kdnuggets.com/2018/02/google-colab-free-gpu-tutorial-tensorflow-keras-pytorch.html\">KDnuggets.</a> Recomiendo ampliamente darle una hojeada para entender mejor como funciona.<br><br>\n",
    "    Para hacer mas sencillo el código, se utilizará Keras con backend TensorFlow, lo cual hace el modelo muy fácil de armar, depurar y leer. La data está almacenada en mi Google Drive, la compartiré en cuanto esté seguro que tengo permiso de hacerlo, igual la data original es accesible en el link de la sección \"Data Utilizada\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Estableciendo la conexión con nuestro Google Drive</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
